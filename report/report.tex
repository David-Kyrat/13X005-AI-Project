% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{preamble_ai_project}
\usepackage[backend=bibtex,style=numeric]{biblatex}
\bibliography{references}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newcommand{\w}{\mathbf{w}}
\newcommand{\x}{\mathbf{x}}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  colorlinks=true,
  linkcolor={Blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\intro{}

\hypertarget{introduction-rappels-thuxe9oriques}{%
\section{1 -- Introduction \& Rappels
théoriques}\label{introduction-rappels-thuxe9oriques}}

Dans ce document, nous approfondirons des techniques de regression
logistique et ``Naive Bayes'' comme outils d'apprentissage superivisés.

Dans le cadre de l'intelligence artificielle et de l'apprentissage
supervisé, la compréhension et la classification précises des données
revêtent une importance capitale. Parmi les diverses méthodologies
existantes, la Régression Logistique et ``Naive Bayes'' se distinguent
par leur efficacité et leur applicabilité dans de nombreux contextes. Ce
document se propose d'étudier ces deux techniques, en mettant l'accent
sur leur mise en œuvre pratique, et leur efficacité comparative dans
divers scénarios.

\hypertarget{ruxe9gression-logistique}{%
\subsection{1.1 -- Régression
Logistique}\label{ruxe9gression-logistique}}

En statistiques, la régression logistique, s'inscrit dans le cadre des
modèles de régression pour les variables binaires. Bien qu'elle soit
quasiment exclusivement utilisée en tant que méthode de
classification.\\
En effet, c'est l'ajout d'un seuil, à la probabilité continue donnée par
le model de regression qui nous permet de l'utiliser pour la
classification.

Ce type de modèle vise à expliquer de manière optimale une variable
binaire, qui représente la présence ou l'absence d'une caractéristique
spécifique, à l'aide d'un ensemble conséquent de données réelles et d'un
modèle mathématique.

Autrement dit, il s'agit de relier une variable aléatoire de Bernoulli,
généralement notée \(y\), aussi appelé ``label'' à un vecteur constitué
de plusieurs variables aléatoires, \((x_1, \ldots, x_K)\), aussi appelés
``features''. \cite{RegressionLogistique2023}.

La régression logistique s'appuie sur un classifeur linéaire
\cite{ClassifieurLineaire2022} i.e.~un classifieur dont la sortie (pour
un vecteur de feature \(x \in \R^n\)) est donnée par:

\[
g(x) = f(\scalproduct{w}{x} + b)
\] où \(w \in \R^n\) est le vecteur de poids, \(b \in \R\) le biais et
\(\scalproduct{.}{.}\) le produit scalair usuel. \(f\) est une fonction
dite de seuillage qui va séparer nos résultats. Un choix commun pour
\(f\) est la sigmoide ou la fonction signe
\cite{ClassifieurLineaire2022}.

Par exemple, dans le cas de la regression logistique binaire, on suppose
le modèle suivant:

\[
y_i \sim Bernoulli(p_i),\quad p_i = \sigma(\scalproduct{\mathbf{w}}{\mathbf{x}_i} + b),\quad \sigma(z) = \frac{1}{1 + e^{-z}}
\] où \(\mathbf{x}_i \in \R^K\) représente un vecteur (ligne) de \(K\)
valeurs pour les \(K\) features (aussi appelé un \emph{sample}), et
\(y_i\) la variable aléatoire qui représente le label qui leur est
associé.

Cependant, dans notre dataset (voir
\href{#choix-du-dataset-outils-utilisuxe9s}{section 2.0}) nous avons 3
classes (3 espèces d'iris), \(y\) ne suit donc, évidemment, plus une loi
de Bernoulli.

\textbf{À modifier ?} La sigmoide étant continue, nous avons simplement
modifié la manière dont nous lui appliquions le seuillage, pour
distinguer 3 cas au lieu de 2. i.e.~Au lieu de séparer le domaine en 2
(\(\sigma(z) \leq 0.5,\ \sigma(z) > 0.5\)), nous l'avons séparé en \(N\)
(ici \(N = 3\)). On a donc que
\(y_i = k \Leftrightarrow \frac{k}{N} \leq \sigma(z) < \frac{k + 1}{N}\),
ce qui a donné des résultats plus que satisfaisants comme nous le
verrons en \href{#ruxe9gression-logistique-1}{section 2.2}.

\hypertarget{naive-bayes}{%
\subsection{1.2 -- Naive Bayes}\label{naive-bayes}}

``Naive Bayes'' se présente comme une méthode de classification
probabiliste basée sur le
\href{https://en.wikipedia.org/wiki/Bayes\%27_theorem}{théorème de
Bayes}, caractérisée par l'adoption d'une hypothèse d'indépendance forte
entre les features (attributs), qualifiée de ``naïve''.\\
Plus simplement, le classifieur est classifié de ``naïf'' car il part du
principe que chaque feature (attribut) est indépendante des autres et a
un poid égal quant à la probabilité qu'un point appartienne à une
classe.

Ce model est dit génératif contrairement à la regression logistique
étant considéré comme ``méthode discriminante''
\cite{ClassifieurLineaire2022} et consiste à modéliser les probabilités
conditionnelles \(P(\mathbf{x}| classe)\) pour chaque classe \(y\) et
smaple \(\mathbf{x}\) afin de trouver celle qui maximise cette
probabilité.

En d'autres termes, le problème revient à trouver, pour des attributs
\(x_1, \ldots, x_k\), la classe \(\tilde{y}\) telle que:

\[
\tilde{y} = \text{arg}\max_{y \in \mathcal{Y}} \left[\  P(y) \prod_{k = 1}^K{P(x_k | Y)}\  \right]
\]

\hypertarget{muxe9thodologie}{%
\section{2 -- Méthodologie}\label{muxe9thodologie}}

\hypertarget{choix-du-dataset-outils-utilisuxe9s}{%
\subsection{2.0 -- Choix du dataset \& outils
utilisés}\label{choix-du-dataset-outils-utilisuxe9s}}

Pour la suite de ce projet les outils suivants ont été utilisés dans
chaque parties:

\begin{itemize}
\tightlist
\item
  \href{https://www.python.org/}{python}
\item
  \href{https://python-poetry.org/}{poetry}
\item
  \href{https://www.gnu.org/software/make/}{Make}
\item
  \href{https://numpy.org/}{numpy}
\item
  \href{https://pandas.pydata.org/}{pandas}
\item
  \href{https://scikit-learn.org/stable/}{sklearn}
\item
  \href{https://matplotlib.org/}{matplotlib}
\item
  \href{https://github.com/uci-ml-repo/ucimlrepo}{ucmilrepo}
\item
  \href{https://docs.pytest.org/en/stable/}{pytest}
\end{itemize}

Le package \texttt{ucmilrepo} a été utilisé pour charger les données de
notre dataset depuis la base de donnée du
\href{https://archive.ics.uci.edu/ml/index}{UC Irvine Machine Learning
Repository}.

Le dataset que nous avons choisi est le fameux dataset ``Iris''
\cite{r.a.fisherIris1936}, un des plus anciens et connus dataset de
classification. Il contient 150 observations de 3 espèces différentes
d'iris (Iris setosa, Iris virginica et Iris versicolor) avec \(K = 4\)
features (longueur et largeur des sépales et pétales).

Voici un aperçu des points-clés du dataset:

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth,height=\textheight]{../res/iris_img.png}
\includegraphics[width=0.8\textwidth,height=\textheight]{../res/iris_table.png}
\caption{Iris descriptive table}
\end{figure}

Le label que nous allons prédire sera donc \emph{class}, i.e.~l'espèce
de l'iris.

\newpage

\hypertarget{gradient-descent}{%
\subsection{2.1 -- Gradient Descent}\label{gradient-descent}}

Dans cette section, une implémentation de la ``descente en gradient'' a
été réalisée. La fonction a la signature suivante

\begin{lstlisting}
  def gradient_descent(df, params: NDArray, alpha: float, num_iters: int) -> NDArray:  
\end{lstlisting}

Elle calcule de manière itérative le(s) paramètre(s) \code{params} qui
minimisent la fonction dont \texttt{df} est le gradient avec un ``taux
de convergence'' \code{alpha}.

La fonction a été testé avec la fonction \code{scipy.optimize.fmin}
\cite{ScipyOptimizeFmin} de la librairie \texttt{scipy} sur la fonction
suivante: \[
f(x) = x * \cos(\pi  (x + 1))
\]

avec différents \(x_0 \in \{-\pi, 0, \pi\}\) (valeur initiale de
\code{params}, i.e.~\texttt{NDArray} avec D=0).

Les minimas locaux trouvés par les deux fonctions sont les suivants:

\begin{figure}
\centering
\includegraphics[width=1\textwidth,height=\textheight]{../res/3.1_gradient_descent_minima.png}
\caption{minimas locaux\_gradient descent}
\end{figure}

Ce résultat illustre bien 2 choses: la première est que l'implémentation
de la descente en gradient fonctionne correctement puisque pour chaque
points trouvé par notre fonction est confondu avec celui trouvé par la
fonction de scipy (c'est ce qui donne cette teinte ``grise''). La
deuxième est que la ``qualité'' du minima local (i.e.~la distance avec
le minima globale) dépend fortement de la valeur initiale et ce pour les
deux fonctions.

\newpage{}

\hypertarget{ruxe9gression-logistique-1}{%
\subsection{2.2 -- Régression
Logistique}\label{ruxe9gression-logistique-1}}

\hypertarget{fonction-de-couxfbt-pour-la-ruxe9gression-logistique}{%
\subsubsection{2.2.1 -- Fonction de coût pour la régression
logistique}\label{fonction-de-couxfbt-pour-la-ruxe9gression-logistique}}

Afin d'entraîner les paramètres de la régression logistique, il faut
pouvoir comparer les résultats obtenus par la régression avec les
résultats attendus.

On souhaite définir une fonction à minimiser permettant de trouver les
paramètres optimaux de la régression logistique.

Notre classification se base sur la fonction sigmoïde
\(\sigma(z) = \frac{1}{1 + e^{-z}}\).

Comme la fonction exponnentielle est toujours positive, on a bien que
\(\sigma(z) \in [0, 1]\).

La fonction sigmoïde nous donne la probabilité que l'élément donné
appartienne à un label.

Autrement dit, la fonction sigmoïde est la fonction de répartition de la
régression logistique.

Soit \(Y \in \{0, 1\}\) les différents labels que peut prendre l'élément
que l'on considère et soit \(X\) l'ensemble des caractéristiques connues
de l'élément, dont on cherche à déterminer dans quelle classe le mettre,
donc quel label on doit lui attribuer. Soit \(\theta\) le vecteur des
poids des covariables, indiquant à quel point les covariables
influencent sur la décision du label. On a donc:

\[P(Y = 1 | X) = \frac{1}{1 + e^{-(X_1 * w_1 + X_2*w_2 + \dots + b)}}\]
et \[P(Y = 0 | X) = 1 - \frac{1}{1 + e^{-(X_1 * w_1 + \dots + b)}}\]

Pour plus de simplicité, on va considérer que le biais est compris dans
les poids: au lieu d'écrire \(z = wX + b\), on écrit
\(z = \hat{X}\theta\) avec
\(\hat{X} = \begin{bmatrix} X & 1 \end{bmatrix}\) modifié ou on a ajouté
une colonne avec que des \(1\) à la fin de la matrice \(X\) et
\(\theta = \begin{bmatrix} w & b \end{bmatrix}\) afin d'avoir une bonne
cohérence avec le rapport et le code. (On a trouvé cela plus facile
d'avoir pour chaque labels les poids et bias sur une ligne, donc d'avoir
\(\theta_1\) pour le label \(1\) etc\ldots) Ainsi, on a:
\(\hat{X} \theta^T = X_1 * w_1 + X_2 * w_2 + \dots + b\)

Pour la suite, on va noter \(X = \hat{X}\)

Notre régression logistique binaire peut donc s'écrire comme:
\[P(Y = 1 | X) = \frac{1}{1 + e^{X \theta^T}} = \sigma(X \theta^T)\] et
\[P(Y = 0 | X) = 1 - \sigma(X \theta^T)\]

\hypertarget{guxe9nuxe9ralisation}{%
\paragraph{2.2.1.1 -- Généralisation}\label{guxe9nuxe9ralisation}}

On désire donc trouver une nouvelle distribution \(\phi(z)\) tel que:
\[\phi(z) \in [0, 1]\ \forall z\] est une généralisation de la fonction
\(\sigma(z)\)

On veut donc que pour une régression logistique binaire, on ait
\(\sigma(z) = \phi(z)\).

On peut remarquer que:

\[P(Y = 1 | X)\] \[=\frac{1}{1 + e^{-X \theta^T}}\]
\[=\frac{1}{1 + e^{-X \theta^T}} * \frac{e^{X \theta^T}}{e^{X \theta^T}}\]
\[=\frac{e^{X \theta^T}}{e^{X \theta^T} + e^{X \theta^T - X \theta^T}}\]
\[=\frac{e^{X \theta^T}}{e^{X \theta^T} + e^0}\]
\[=\frac{e^{X \theta^T}}{e^{X \theta^T} + 1}\]

On peut considérer que nous avons un vecteur de poids pour chaque label.

Ainsi, on a \(\theta_0 = \begin{bmatrix} w_0 & b_0 \end{bmatrix}\) pour
le label 0 et \(\theta_1 = \begin{bmatrix} w_0 & b_0 \end{bmatrix}\)
pour le label 1.

Comme on a besoin seulement d'un vecteur de poids pour déterminer le
label de nouveaux éléments avec leurs caractéristiques, on peut
considérer que
\(\theta_0 = \begin{bmatrix} 0 & \dots & 0 \end{bmatrix}\).

Ainsi, la formule précédente nous donne:

\[P(Y = 1 | X)\] \[=\frac{e^{X \theta_1^T}}{e^{X \theta_1^T} + 1}\]
\[=\frac{e^{X \theta_1^T}}{e^{X \theta_1^T} + e^0}\]
\[=\frac{e^{X \theta_1^T}}{e^{X \theta_1^T} + e^{0 * X}}\]
\[=\frac{e^{X \theta_1^T}}{e^{X \theta_1^T} + e^{X \theta_0^T}}\]
\[=\frac{e^{X \theta_1^T}}{\sum_{i = 0}^1 e^{X \theta_i^T}}\]

On peut donc généraliser cette formule pour \(K\) labels.

Cela nous donne:

\[P(Y = k| X )=\frac{e^{X \theta_k^T}}{\sum_{i = 0}^K e^{X \theta_i^T}}\]

Comme la fonction exponentielle est toujours positive, on a bien que:
\[0 \leq e^{X \theta_k^T} \leq e^{X \theta_k^T} + \sum_{i \neq k}^K e^{X \theta_i^T}\]
\[\Leftrightarrow 0 \leq e^{X \theta_k^T} \leq \sum_{i}^K e^{X \theta_i^T}\]
\[\Leftrightarrow 0 \leq \frac{e^{X \theta_k^T}}{\sum_{i}^K e^{X \theta_i^T}} \leq 1\]
\[\Leftrightarrow 0 \leq \phi(z) \leq 1\]

De plus, on a que: \[\sum_k^K P(Y = k | X)\]
\[=\sum_k^K \frac{e^{X \theta_k^T}}{\sum_i^K e^{X \theta_i^T}}\]
\[=\frac{\sum_k^Ke^{X \theta_k^T}}{\sum_i^K e^{X \theta_i^T}}\]
\[=\frac{\sum_i^Ke^{X \theta_i^T}}{\sum_i^K e^{X \theta_i^T}}\] \[=1\]

Donc la fonction \(\phi(z)\) est bien une fonction de distribution de
probabilité qui généralise la fonction sigmoïde pour des problèmes à
plusieurs labels.

Cette fonction est courramment appelée fonction \texttt{softmax}.

\hypertarget{fonction-de-couxfbt}{%
\paragraph{2.2.1.2 -- Fonction de coût}\label{fonction-de-couxfbt}}

Notre objectif est donc de trouver une fonction de coût pour pouvoir
entraîner les paramètres de la régression multinomiale. On cherche à
maximiser la vraisemblance des données. Donc pour un label \(Y\) donné,
on veut maximiser: \[\sum_k^K f(Y, k) P(Y = k | X)\] avec \(f(Y, k)\) la
fonction qui vaut \(1\) si \(Y = k\) et \(0\) sinon.

Comme on a plusieurs couples de données \((X_i, Y_i)\), on peut écrire
la fonction précédente comme:

\[\sum_i^n\sum_k^K f(Y_i, k) P(Y_i = k | X_i)\]

En maximisant cette fonction, on fait en sorte que le paramètre
\(\theta_k\) permette d'obtenir la prédiction que le label soit égal à
\(k\) avec la somme des probabilités où \(Y_i = k\) est la plus grande
possible.

Afin de pouvoir utiliser un algorithme comme la descente en gradient, il
faut non pas maximiser une fonction, mais minimiser une fonction.

Tout d'abord, comme on travaille avec des exponentielles, on a intérêt à
prendre un logarithme pour éviter d'avoir à travailler avec de trop
grandes valeurs. Cette modification n'aura pas d'impact sur la convexité
car la fonction logarithme est une fonction strictement croissante.

Enfin, comme on cherche une fonction à minimiser et non pas à maximiser
pour pouvoir utiliser la descente en gradient, on va prendre l'inverse
de la fonction.

Cela s'appelle courrament le \texttt{negative\ logarithm\ likelihood}.

Cela nous donne une fonction de coût comme suit:

\[\sum_i^n \sum_k^K f(Y_i, k) \log(\frac{1}{P(Y_i = k | X_i)})\]
\[\sum_i^n \sum_k^K f(Y_i, k) (\log(1) - \log(P(Y_i = k | X_i)))\]
\[-\sum_i^n \sum_k^K f(Y, k)\log(P(Y_i = k | X_i))\]

On peut minimiser cette fonction de coût grâce à une descente en
gradient.

\hypertarget{duxe9rivuxe9e-de-la-fonction-de-couxfbt}{%
\paragraph{2.2.1.3 -- Dérivée de la fonction de
coût}\label{duxe9rivuxe9e-de-la-fonction-de-couxfbt}}

On va calculer la dérivée de la fonction de coût.

On a:

\[log(P(Y = k | X))\]
\[=log\left(\frac{e^{X \theta_k^T}}{\sum_i^K e^{X\theta_i^T}}\right)\]
\[=X \theta_k^T - log\left(\sum_i^K e^{X \theta_i^T}\right)\]

Donc:
\[\frac{\partial}{\partial \theta_{j}} \sum_i^K f(Y, i)log(P(Y = i | X))\]
\[\text{(NB: On considère que Y = k, tous les autres termes étant annulés car f = 0)}\]
\[=\frac{\partial}{\partial \theta_{j}} f(Y, k)log(P(Y = k | X))\]
\[=\frac{\partial}{\partial \theta_{j}} \left(X \theta_{k}^T - log\left(\sum_i^K e^{X \theta_i^T}\right)\right) \]
Supposons que j = k.
\[=X - \frac{\partial}{\partial \theta_{j}}log\left(\sum_i^K e^{X \theta_i^T}\right) \]
\[=X - \frac{1}{\sum_i^K e^{X \theta_i^T}} \frac{\partial}{\partial \theta_{j}}\sum_i^K e^{X \theta_i^T} \]
\[=X - \frac{1}{\sum_i^K e^{X \theta_i^T}} \frac{\partial}{\partial \theta_{j}}e^{X \theta_j^T}\]
\[=X - \frac{X e^{X \theta_j^T}}{\sum_i^K e^{X \theta_i^T}}\]
\[=X - X P(Y = j | X)\] \[=X (1 - P(Y = j | X))\] Supposons que
\(j \neq k\).

\[\frac{\partial}{\partial \theta_{j}} \left(X \theta_{k}^T - log\left(\sum_i^K e^{X \theta_i^T}\right)\right) \]
\[= - \frac{\partial}{\partial \theta_{j}}log\left(\sum_i^K e^{X \theta_i^T}\right) \]
\[= - \frac{1}{\sum_i^K e^{X \theta_i^T}} \frac{\partial}{\partial \theta_{j}}\sum_i^K e^{X \theta_i^T} \]
\[= - \frac{1}{\sum_i^K e^{X \theta_i^T}} \frac{\partial}{\partial \theta_{j}}e^{X \theta_j^T} \]
\[= - \frac{Xe^{X \theta_j^T}}{\sum_i^K e^{X \theta_i^T}} \]
\[= -X P(Y = j | X)\]

On a donc:
\[\frac{\partial}{\partial \theta_{j}} \sum_i^K f(Y, i)log(P(Y = i | X)) = X(f(Y, j) - P(Y = j|X))\]

car \(f(Y, k)\) est égal à 1 si \(Y = k\) et 0 sinon.

Donc pour \(n\) données, cela nous donne:
\[\frac{\partial}{\partial \theta_{j}} \sum_m^n \sum_i^K f(Y_m, i)log(P(Y_m = i | X_m)) = \sum_m^n X_m(f(Y_m, j) - P(Y_m = j|X_m))\]

Maintenant, on est prêt pour entraîner notre régression logistique
multinomiale !

\hypertarget{apprentissage}{%
\subsubsection{2.2.2 -- Apprentissage}\label{apprentissage}}

Maitenant que nous avons une fonction de coût permettant de quantifier
(en moyenne) à quel point un set de \(N\) prédiction est
correct/incorrect à un point de l'apprentissage donné. Il ne reste plus
qu'à chercher les paramètres optimaux qui minimisent cette fonction de
coût. Ce que l'on va réaliser à l'aide de la descente en gradient. C'est
le processus d'apprentissage.

En effet, lors de l'apprentissage, on va chercher de manière itérative
les \(\mathbf{w}\) et \(b\) qui respectent les critères mentionnés
ci-dessus en calculant le gradient de la fonction de coût à chaque
itérations et en allant dans la direction opposé.

Concrètement cela revient à appliquer l'algorithme suivant:

\begin{algorithm}
\caption{gradient descent}\label{alg:grad_desc}
\begin{algorithmic}
\Function {GradientDescent}{$f, \mathbf{w}_{init}, b_0, \alpha, \text{num\_iters}$}
\State $\mathbf{w}\gets \mathbf{w}_{init}$
\State $b \gets b_0$
\For{1 to num\_iters}
    \State $\mathbf{dw}, db \gets \nabla{f(w, b)} $
    \State $\mathbf{w}\gets \mathbf{w}- \alpha*\mathbf{dw}$
    \State $b \gets b - \alpha*db$
\EndFor
\State \Return $w, b$
\EndFunction
\end{algorithmic}
\end{algorithm}

En pratique, il est plus simple de passer directement la function qui
calcul le gradient en argument, que d'essayer de le calculer
dynamiquement, c'est pourquoi la signature de notre implémentation prend
un \texttt{df} en argument plutôt que la fonction de coût elle même.\\
Où le calcul des dérivées partielles a été definit comme ci-dessous.

Soit
\(\nabla C(\mathbf{w},b) = (\frac{\partial C(\mathbf{w},b)}{\partial \mathbf{w}}, \frac{\partial C(\mathbf{w},b)}{\partial b} )\),
pour un sample \(\mathbf{x}_i\) et sa classe \(y_i\), on obtient:
\begin{align*}
\frac{\partial \log(y_i|\mathbf{x}_i ; \mathbf{w}, b)}{\partial b} 
&= y_i - \sigma(z_i) 
= y_i - \sigma(\mathbf{w}^T X_i + b)\\
%
\frac{\partial \log(y_i|\mathbf{x}_i ; \mathbf{w}, b)}{\partial w_j} 
&= x_{ij}* ( y_i - \sigma(z_i)) 
= (y_i - \sigma(\mathbf{w}^T X_i + b)) * x_{ij}
\end{align*} Or le \texttt{db} dans l'algorithme ci-dessus se refert à
la moyenne (pour tout i) de ces valeurs (i.e.~distance moyenne
\emph{classes prédites} -- \emph{``vrai'' classes}).

On l'obtient donc comme suit: (la somme des dérivées est la dérivée de
la somme, linéarité de la dérivée)
\[\nabla_b\, {C} =\frac{1}{N} \sum_{i = 1}^{N}{ \frac{\partial \log(y_i|\mathbf{x}_i ; \mathbf{w}, b)}{\partial b} =  \frac{1}{N} \sum_{i=1}^N{y_i - \sigma(\mathbf{w}^T X_i + b)}}\]

De même pour \texttt{dw}: \begin{align*}
  \nabla_{\mathbf{w}} C & = \frac{1}{N} \sum_{i = 1}^{N}(x_{ij}(y_i - p_i))_{1 \leq j \leq k} 
  = \frac{1}{N} \sum_{i=1}^N(y_i - \sigma(z_i))\cdot (x_{ij})_{1 \leq j\leq k} \\
%
& =\frac{1}{N}\sum_{i = 1}^N (y_i - \sigma(\mathbf{w}^T\mathbf{x_i} + b))\ \mathbf{x_i}
\end{align*}

On retrouve ainsi, le calcul effectué dans la fonction \code{grad} de
\code{log\_reg.py} de signature suivante:

\begin{lstlisting}
    def grad(X: NDArray, y: NDArray, w: NDArray, b: float) -> tuple:
\end{lstlisting}

Etant donné que pour le calcul du gradient il est nécessaire d'avoir un
matrice de feature \(X\) et vecteur de label \(y\), une version
``modifiée'' de la descente en gradient a été implementé.

\begin{lstlisting}
def grad_desc_ml(features: NDArray, labels: NDArray, df, w: NDArray, b: float, alpha: float, num_iters: int) -> tuple[NDArray, float]:
\end{lstlisting}

Cette fonction se comporte exactement de la même manière que celle
décrite en \href{#gradient-descent}{section 2.1}. La seule différence
est qu'elle passe \texttt{features} et \texttt{labels} comme \texttt{X}
et \texttt{y} à la fonction \texttt{df} (dans notre cas \texttt{df} est
toujours la fonction \texttt{grad}), i.e.~on a
\code{df(features, labels, w, b)} au lieu de \code{df(params)}.

\hypertarget{pruxe9dictions}{%
\subsubsection{2.2.3 -- Prédictions}\label{pruxe9dictions}}

Pour la prédiction, nous avons utilisé la fonction suivante:

\begin{lstlisting}
   def predict_log_reg(X: NDArray, w: NDArray, b):
\end{lstlisting}

qui prend simplement \(\sigma(w^T X + b)\) et seuil la sortie du
sigmoide de manière à retourner un nombre entre 0 et 2 (avec les poids
et bais entraînés).

\newpage{}

\hypertarget{ruxe9sultats}{%
\subsubsection{2.2.4 -- Résultats}\label{ruxe9sultats}}

Suite à l'apprentissage , nous avons obtenu les résultats suivants:
\begin{align*}
    w &= [0.53452349, 0.36463584, 1.16132476, 1.08204578]\\
    b &= 0.45146791
\end{align*}

\begin{quote}
N.B.:\\
L'apprentissage peut être ré-effectué de manière efficient si besoine
est à l'aide du jupyter notebook
\href{https://github.com/David-Kyrat/13X005-AI-Project/blob/gpu-training/training_test.ipynb}{training\_test.ipynb}
disponible sur la branche
\href{https://github.com/David-Kyrat/13X005-AI-Project/blob/gpu-training/training_test.ipynb}{gpu-training}
du repository github. Le code de l'entraînement (uniquement sur cette
branche) à été ``porté'' sur cuda / gpgpu à l'aide de la librairie
\href{https://cupy.dev}{cupy} \cite{NumPySciPyGPU}.\\
A noter qu'il utilise des fonctions des sklearn alors que nous devions
les implémenter nous mêmes, (telles que les metrics f1-score\ldots). Ces
fonctions ont bien été implenté mais pour une raison de simplicité, elle
n'ont pas été utilisée pour l'entrainement. Le code de cette branche ne
fera donc pas partie du rendu mais reste publiquement accessible sur
github.
\end{quote}

\vspace{0.3cm}

Comme dit en section 1.1, ces paramètres sont, en effet, plus que
satisfaisants, comme on peut le voir sur l'output de \texttt{pytest}
suivant:

\begin{lstlisting}
src/log_reg.py::test_log_reg_f1score 
weights & biases: [0.53452349, 0.36463584, 1.16132476, 1.08204578], 0.45146791  
{ 'accuracy': 1.0, 'f1_score': 1.0, 'precision': 1.0, 'recall': 1.0 }
PASSED

src/naive_bayes.py::test_predict_bayes_f1score_all  
{ 'accuracy': 0.97, 'f1_score': 0.975, 'precision': 0.976, 'recall': 0.974 }
PASSED
\end{lstlisting}

NB: pour reproduire cette output, lancer \code{make test\_model}.

Ce résultat a été obtenu avec une séparation 70/30 de training/test
data. Lorsque l'on essaye de changer la portion qui est prise
aléatoirement dans chaque catégorie, on obtient un F1-score qui varie
entre 0.93 et 1.0 (avec, dans de rares exceptions 0.91 ou 0.89).

De plus, l'on voit que les performances que nous avons obtenus rentrent
tout à fait dans le cadre de celles annoncées par le UCI ML Repository:

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth,height=\textheight]{../res/screenshot_ucmi_perfs.png}
\caption{performances attendu d'après le UCI ML Repo \cite{IrisWebsite}}
\end{figure}

Ce résultat illustre bien que notre démarche est correcte et que nos 2
modèles sont efficaces, avec un penchant pour la régression logistique
qui semble être plus efficace que Naive Bayes.

\newpage{}

\hypertarget{naive-bayes-1}{%
\subsection{2.3 -- Naive Bayes}\label{naive-bayes-1}}

Dans cette section, une implémentation d'un classifieur linéaire
bayesien (naive bayes) a été réalisée.

\hypertarget{extraction-des-distributions}{%
\subsubsection{2.3.1 -- Extraction des
distributions}\label{extraction-des-distributions}}

Dans cette implémentation, étant données que toutes nos features sont
continues, nous avons considéré que \emph{sepal length}, \emph{sepal
width}, \emph{petal length} et \emph{petal width} seront représenté
comme 4 variables aléatoires \(X_0, \cdots, X_3\) suivant 4 lois
normales normales de paramètre \((\mu_k, \sigma_k)\).

C'est à dire: \[
X_k \sim \mathcal{N}( \mu_k, \sigma_k) \qquad \qquad k \in \iitv{0, 3}
\]

Elles peuvent être récupérées à l'aide de la fonction suivante:

\begin{lstlisting}
def get_distrib_parameters(features: DataFrame, labels) -> dict[Any, list[tuple[fl, fl]]]:
\end{lstlisting}

qui va retourner un dict mappant chaque classe à une liste contenant les
paramètres des distributions conditionnelles (normales) des features
pour cette classe.

\hypertarget{pruxe9dictions-1}{%
\subsubsection{2.3.2 -- Prédictions}\label{pruxe9dictions-1}}

Deux fonctions de prédictions ont été implémenté,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Prennant un sample et prédisant sa classe
\item
  Une deuxième qui prend tous les samples et applique, en parallèle, la
  première fonction à chacun d'eux.
\end{enumerate}

Elles ont les signatures suivantes:

\begin{lstlisting}
    def predict_bayes(x, params_by_class: dict[Any, list[tuple[fl, fl]]]) -> Any:
    def predict_bayes_all(X: DataFrame, params_by_class: dict[Any, list[tuple[fl, fl]]] | None = None) -> list[Any]:
\end{lstlisting}

Comme dit précédemment, pour pouvoir prédire la classe d'un sample, il
faut calculer les probabilité conditionnelle \(P(\mathbf{x}| classe)\)
pour chaque classe \(y\) et sample \(\mathbf{x}\) et prendre la classe
qui maximise cette dernière.

Cela revient à chercher le \(\tilde{y}\) défini en
\href{#naive-bayes}{section 1.2}, développons le calcul qui nous amené à
cette formule:

\[
\tilde{y}  = \text{arg}\max_{y \in \mathcal{Y}}\ P(y|\mathbf{x}) = \text{arg}\max_{y \in \mathcal{Y}}\ \frac{P(\mathbf{x}|y)  P(y)}{P(\mathbf{x})} =  \text{arg}\max_{y \in \mathcal{Y}}\ P(\mathbf{x}| y)P(y)
\]

Or \[ 
P(\mathbf{x}| y) = P(x_1 | y) \prod_{i = 2}^{n}{P(x_i | x_{i-1}, \ldots, x_1, y)}
\] Avec l'hypothèse que les \(\{X_i\}_{i \leq n}\) sont indépendants, on
obtient que:

\[P(x_i | x_{i-1}, \ldots, x_1, y) = P(x_i | y)\]

Donc
\[P(\mathbf{x}|y) = P(x_1 | y) \prod_{k = 2}^{K}{P(x_k | y)} = \prod_{k=1}^K{P(x_k | y)}\]

En conclusion:
\[ \tilde{y} = \text{arg}\max_{y \in \mathcal{Y}} \left[\  P(y) \prod_{k = 1}^K{P(x_k | y)}\  \right] \]
(où \(K\) reste le nombre de features.)

Où au début on cherche à maximiser \(P(y | x)\) car idéalement on
voudrait savoir la probabilité que \(y\) soit le bon label pour
n'importe quel sample \(\mathbf{x}\). Cependant, on aimerait pouvoir
effectuer cette prédictions pour des \(\mathbf{x}\) qui n'appartiennent
pas à notre dataset d'apprentissage, i.e.~on ne doit pas avoir besoin
d'avoir déjà vu exactement ce sample. On a donc besoin d'une
généralisation, c'est ainsi que l'on fini par retomber sur

\[ \tilde{y} = \text{arg}\max_{y \in \mathcal{Y}} \left[\  P(y) \prod_{k = 1}^K{P(x_k | y)}\  \right] \]

qui est ce que calculent les fonctions dont on a donné la signature
ci-dessus.

\hypertarget{ruxe9sultats-1}{%
\subsubsection{2.3.3 -- Résultats}\label{ruxe9sultats-1}}

Dans cette section, nous allons simplement reprendre ce qui a été fait
dit dans la \href{#ruxe9sultats}{section 2.2.4} et remontrer les mêmes
tests.

Voici l'output du test \texttt{pytest} pour les rapports de performances
du model bayesien:

\begin{lstlisting}
src/log_reg.py::test_log_reg_f1score 
weights & biases: [0.53452349, 0.36463584, 1.16132476, 1.08204578], 0.45146791  
{ 'accuracy': 1.0, 'f1_score': 1.0, 'precision': 1.0, 'recall': 1.0 }
PASSED

src/naive_bayes.py::test_predict_bayes_f1score_all  
{ 'accuracy': 0.97, 'f1_score': 0.975, 'precision': 0.976, 'recall': 0.974 }
PASSED
\end{lstlisting}

Ce résultat a été obtenu avec une séparation 70/30 de training/test
data.\\
Ces résultats illustrent bien que notre démarche est correcte et que nos
2 modèles sont efficaces, avec un penchant pour la régression logistique
qui semble être plus efficace que Naive Bayes.\\
Cependant, un f1-score de \(> 0.95\) reste excellent.

\newpage{}

\hypertarget{analyse}{%
\section{3. -- Analyse}\label{analyse}}

Pour chaque classe y, on peut tracer les fonctions de distribution de
probabilité pour chaque donnée \(X_k\) sachant la classe y afin
d'analyser la structure des données.

Pour la classe Y=0, on obtient le graphe suivant :

\begin{figure}
\centering
\includegraphics{../src/res/comp_normal_law_Y_0.png}
\caption{graphe des fonctions de distribution sachant Y=0}
\end{figure}

On peut voir tout d'abord que pour cette classe, les pics des courbes
bleue et rouge sont bien inférieurs aux pics des courbes vert et
magenta. Ainsi, on en conclu que les variables \(X_0\) et \(X_1\) ont
moins d'influence dans la prédiction de cette classe. Alors que le pic
de la courbe magenta est bien supérieur aux autres, indiquant que la
variable \(X_3\) a une forte influence sur la prédiction de cette
classe. De plus, on observe que seul les courbent bleu et rouge ont un
chevauchement perceptible mais quand même assez petit, on en conclu que
les variables sont pour cette classe très peu indépendante les unes des
autres.

\newpage{}

Pour la classe Y=1, on obtient le graphe suivant :

\begin{figure}
\centering
\includegraphics{../src/res/comp_normal_law_Y_1.png}
\caption{graphe des fonctions de distribution sachant Y=1}
\end{figure}

On peut voir tout d'abord que pour cette classe, les pics des courbes
bleus et verte sont bien inférieurs aux pics des courbes rouge et
magenta. Ainsi, on en conclu que les variables \(X_0\) et \(X_2\) ont
moins d'influence dans la prédiction de cette classe. Alors que le pic
de la courbe magenta est bien supérieur aux autres, indiquant que la
variable \(X_3\) a une forte influence sur la prédiction de cette
classe. De plus, on observe que les courbes rouge et magenta ont un
faible chevauchement indiquant une faible interdépence entre \(X_3\) et
\(X_1\) alors que les courbes rouge et verte ainsi que verte et bleue
ont un chevauchement assez élevé montrant une certaine interdépendance
entre les variables \(X_1\) et \(X_2\) ainsi qu'entre les variables
\(X_0\) et \(X_2\).

\newpage{}

Enfin pour la classe Y=2, on obtient le graphe suivant :

\begin{figure}
\centering
\includegraphics{../src/res/comp_normal_law_Y_2.png}
\caption{graphe des fonctions de distribution sachant Y=2}
\end{figure}

On observe que les pics des courbes rouge et magenta sont presque deux
fois plus grand que ceux des courbes bleue et verte, de plus les courbes
rouge se chevauchent fortement. Ainsi les variables \(X_3\) et \(X_1\)
ont une très forte influence sur cette classe et sont assez
interdépendant alors que les variables \(X_0\) et \(X_2\) ont très peu
d'impacte sur la prédiction de cette classe. Les courbes bleue et verte
se chevauchent aussi énormément montrant aussi une forte interdépendance
entre les variables \(X_0\) et \(X_2\).

Ainsi on peut remarquer que globalement la variable \(X_3\) a une forte
influence sur la classification alors que la variable \(X_0\) a une plus
faible. De plus, les variables indépendantes ne sont pas séparables les
unes des autres.

\printbibliography[heading=bibintoc, title={Références}]

\end{document}
